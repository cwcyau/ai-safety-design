# AI Safety by Design

## Background

Artificial Intelligence (AI) is software that is capable of performing one or more tasks using processes based on context and information available to it at the time. There are many AI products which have been developed (or are being developed) for medical purposes. AI could be used to analyse medical images, make treatment recommendations and help doctors to create, organise and arrange their entire patient management plan. AI could be potentially highly beneficial for modern healthcare but we currently have insufficient experience of how AI works in practice to be certain in our judgements.

*Safety by design* is a basic principle in everyday engineering. Cars, airplanes, washing machines, and even simple tools are designed from the outset to reduce harm if something goes wrong. As AI systems increasingly influence decisions about people’s lives, including in healthcare. Yet safety is not always built into these systems from the very beginning.

## Purpose

This workshop invites members of the public to explore what "safe AI" should mean in practice. Participants will consider two real-world healthcare scenarios involving AI, each with different possible ways the AI could behave. Together, they will discuss which behaviours feel more acceptable, trustworthy, or concerning — and why.

By the end of the workshop, participants will agree on a small set of safety features that they believe should be built into AI systems from the start, especially when those systems affect human wellbeing.

Participants will:

- gain understanding of the way in which AI is different to conventional software
- discuss the issues that AI poses in these medical settings
- provide a response to future AI for medical design

## Before the workshop

Before the workshop, please read the description of both scenarios and consider the *immediate* questions posed after. You may also consider the other questions which will be discussed during the workshop:

[Scenario 1](scenario1.md) - in this example, we examine a situation in which an AI learns to improve and the consequences for those the AI affects

[Scenario 2](scenario2.md) - in this example, we examine how software upgrades can lead to challenges in assessing the usefulness of the upgrade

